Note: description generated by ChatGPT.
Code examples handwritten, if provided.

# ============================================================
# Class: StandardScaler
# ============================================================
# Standardizes features by removing the mean and scaling to unit variance.
# 
# Highlights:
#   - Works on CPU or CUDA (follows tensor/module device).
#   - Numerically-stable streaming stats via Chan/Welford algorithm.
#   - fit() uses batched passes; partial_fit() updates stats incrementally.
#   - transform() can run as a single big batch or in chunks.
#   - Uses population variance (ddof=0), matching sklearn’s StandardScaler default.
#
# Args:
#   dtype (torch.dtype):
#       Dtype for internal computation and stored statistics. Default: torch.float32.
#   with_mean (bool):
#       If True, centers data by subtracting the learned mean. Default: True.
#   with_std (bool):
#       If True, scales by the learned population standard deviation. Default: True.
#   eps (float):
#       Numerical floor added to variance before sqrt to avoid division by zero. Default: 1e-12.
#
# Attributes:
#   mean_ (Tensor):
#       Per-feature mean, shape (D,). Allocated on first use; follows device/dtype.
#   m2_ (Tensor):
#       Per-feature sum of squared deviations, shape (D,). Internal accumulator.
#   var_ (Tensor):
#       Per-feature population variance, var_ = m2_ / n, shape (D,).
#   scale_ (Tensor):
#       Per-feature population standard deviation, sqrt(var_ + eps), shape (D,).
#   n_samples_seen_ (Tensor):
#       Total number of samples incorporated into the statistics (scalar long tensor).
#   fitted_ (bool):
#       Indicates whether the scaler has seen any data and has valid stats.
#
# Public Methods:
#   partial_fit(X: torch.Tensor) -> StandardScaler
#       Incrementally update running statistics from a mini-batch.
#       Args:
#         X: 2D tensor (B, D).
#       Returns:
#         self
#
#   fit(X: torch.Tensor, batch_size: int = 64) -> StandardScaler
#       Compute running statistics over X in chunks (calls partial_fit internally).
#       Args:
#         X: 2D tensor (N, D).
#         batch_size: Chunk size for streaming (default: 64).
#       Returns:
#         self
#
#   transform(X: torch.Tensor, batch_size: Optional[int] = None) -> torch.Tensor
#       Standardize X using learned mean_ and scale_:
#         X' = (X - mean_) / scale_
#       Args:
#         X: 2D tensor (N, D).
#         batch_size: If None, transform in one pass; otherwise process in chunks.
#       Returns:
#         Standardized tensor (N, D) on the same device as X.
#
#   inverse_transform(X: torch.Tensor, batch_size: Optional[int] = None) -> torch.Tensor
#       Revert standardization:
#         X ≈ X' * scale_ + mean_
#       Args:
#         X: 2D tensor (N, D) in standardized space.
#         batch_size: If None, inverse in one pass; otherwise process in chunks.
#       Returns:
#         Tensor (N, D) in original feature scale on the same device as X.
#
# Usage:
#   scaler = StandardScaler(dtype=torch.float32, with_mean=True, with_std=True)
#   scaler.fit(X_train, batch_size=1024)   # or: for each batch -> scaler.partial_fit(batch)
#   X_train_std = scaler.transform(X_train)
#   X_test_std  = scaler.transform(X_test)
#   X_rec       = scaler.inverse_transform(X_train_std)
